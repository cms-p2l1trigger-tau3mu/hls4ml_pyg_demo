{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bc2776",
   "metadata": {},
   "source": [
    "# Installation\n",
    "Please follow the instructions on README.mk file for installing the necessary packages to run this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b78f5f",
   "metadata": {},
   "source": [
    "This walkthrough has few instructions. It's mainly just code to help the user to understand the pytorch geometric to hls4ml pipeline. If there's any confusion, please email me at yun79@purdue.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1907e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95ed83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e745ebbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 14:07:40.882053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-14 14:07:40.882093: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handler args: ('NodeBlock',)\n",
      "handler args: ('EdgeAggregate',)\n",
      "handler args: ('ResidualBlock',)\n",
      "handler args: ('NodeEncoder',)\n",
      "handler args: ('EdgeEncoder',)\n",
      "handler args: ('NodeEncoderBatchNorm1d',)\n",
      "handler args: ('EdgeEncoderBatchNorm1d',)\n",
      "handler args: ('MeanPool',)\n",
      "handler args: ('fc_out',)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from hls4ml.utils.config import config_from_pyg_model\n",
    "from hls4ml.converters import convert_from_pyg_model\n",
    "import hls4ml\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# locals\n",
    "from utils.models.interaction_network_pyg import GENConvBig\n",
    "from model_wrappers import model_wrapper\n",
    "from utils.data.dataset_pyg import GraphDataset\n",
    "from utils.data.fix_graph_size import fix_graph_size\n",
    "import time\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb118bac",
   "metadata": {},
   "source": [
    "### PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6489e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_parameters(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    print(f\"N Model Parameters: {pp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "24082fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We intialize our custom pytorch geometric(pyg) model\n",
    "\"\"\"\n",
    "n_layers = 1\n",
    "out_channels = 1\n",
    "torch_model = GENConvBig(\n",
    "    n_layers, \n",
    "    flow = \"source_to_target\",\n",
    "    out_channels = out_channels,\n",
    "    debugging = True\n",
    ").eval() # eval mode for bathnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c40f706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Model Parameters: 26\n"
     ]
    }
   ],
   "source": [
    "number_of_parameters(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "767aab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model.node_encoder_norm.weight = nn.Parameter(\n",
    "    torch_model.node_encoder_norm.norm.weight\n",
    ")\n",
    "\n",
    "torch_model.node_encoder_norm.bias = nn.Parameter(\n",
    "    torch_model.node_encoder_norm.norm.bias\n",
    ")\n",
    "\n",
    "torch_model.node_encoder_norm.running_mean = nn.Parameter(\n",
    "    torch_model.node_encoder_norm.norm.running_mean\n",
    ")\n",
    "\n",
    "torch_model.node_encoder_norm.running_var = nn.Parameter(\n",
    "    torch_model.node_encoder_norm.norm.running_var\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68dca9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model.edge_encoder_norm.weight = nn.Parameter(\n",
    "    torch_model.edge_encoder_norm.norm.weight\n",
    ")\n",
    "\n",
    "torch_model.edge_encoder_norm.bias = nn.Parameter(\n",
    "    torch_model.edge_encoder_norm.norm.bias\n",
    ")\n",
    "\n",
    "torch_model.edge_encoder_norm.running_mean = nn.Parameter(\n",
    "    torch_model.edge_encoder_norm.norm.running_mean\n",
    ")\n",
    "\n",
    "torch_model.edge_encoder_norm.running_var = nn.Parameter(\n",
    "    torch_model.edge_encoder_norm.norm.running_var\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7e8ca2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Betas = []\n",
    "for nodeblock_idx in range(n_layers):\n",
    "    gnn = torch_model.gnns[nodeblock_idx]\n",
    "    Betas.append(float(gnn.beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49e754",
   "metadata": {},
   "source": [
    "### HLS Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2497dd99",
   "metadata": {},
   "source": [
    "hls4ml cannot infer the *order* in which these submodules are called within the pytorch model's \"forward()\" function. We have to manually define this information in the form of an ordered-dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "18b64da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward_dict: defines the order in which graph-blocks are called in the model's 'forward()' method\n",
    "\"\"\"\n",
    "forward_dict = OrderedDict()\n",
    "forward_dict[\"node_encoder\"] = \"NodeEncoder\"\n",
    "forward_dict[\"edge_encoder\"] = \"EdgeEncoder\"\n",
    "forward_dict[\"node_encoder_norm\"] = \"NodeEncoderBatchNorm1d\"\n",
    "forward_dict[\"edge_encoder_norm\"] = \"EdgeEncoderBatchNorm1d\"\n",
    "for nodeblock_idx in range(n_layers):\n",
    "    forward_dict[f\"O_{nodeblock_idx}\"] = \"NodeBlock\"\n",
    "forward_dict[\"pool\"] = \"MeanPool\"  \n",
    "forward_dict[\"fc_out\"] = \"fc_out\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf43159",
   "metadata": {},
   "source": [
    "hls4ml creates a hardware implementation of the GNN, which can only be represented using fixed-size arrays. This restriction also applies to the inputs and outputs of the GNN, so we must define the size of the graphs that this hardware GNN can take as input**, again in the form of a dictionary. \n",
    "\n",
    "**Graphs of a different size can be padded or truncated to the appropriate size using the \"fix_graph_size\" function. In this notebook, padding/truncation is  done in the \"Data\" cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "baa5a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we define additional parameters.\n",
    "\"\"\"\n",
    "common_dim = out_channels\n",
    "graph_dims = {\n",
    "        \"n_node\": 28,\n",
    "        \"n_edge\": 37,\n",
    "        \"node_attr\": 3,\n",
    "        \"node_dim\": common_dim,\n",
    "        \"edge_attr\": 4,\n",
    "    \"edge_dim\":common_dim\n",
    "}\n",
    "\n",
    "misc_config = {\"Betas\" : Betas}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943157a",
   "metadata": {},
   "source": [
    "Armed with our pytorch model and these two dictionaries**, we can create the HLS model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59aa1957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'Model': {'Precision': 'ap_fixed<52,20>', 'IndexPrecision': 'ap_uint<16>', 'ReuseFactor': 8, 'Strategy': 'Latency'}}\n",
      "self.torch_model: GENConvBig(\n",
      "  (node_encoder): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (node_encoder_norm): NodeEncoderBatchNorm1d(\n",
      "    (norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (edge_encoder): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (edge_encoder_norm): EdgeEncoderBatchNorm1d(\n",
      "    (norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (gnns): ModuleList(\n",
      "    (0): GENConvSmall()\n",
      "  )\n",
      "  (O_0): ObjectModel(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "      (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): Linear(in_features=2, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc_out): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "misc_config: {'Betas': [0.01]}\n"
     ]
    }
   ],
   "source": [
    "from hls4ml.model.optimizer import get_available_passes\n",
    "\"\"\"\n",
    "We initialize hls model from pyg model\n",
    "\"\"\"\n",
    "output_dir = \"test_GNN\"\n",
    "config = config_from_pyg_model(torch_model,\n",
    "                                   default_precision=\"ap_fixed<52,20>\",\n",
    "                                   default_index_precision='ap_uint<16>', \n",
    "                                   default_reuse_factor=8)\n",
    "\n",
    "# config[\"Optimizers\"] = get_available_passes()\n",
    "\n",
    "print(f\"config: {config}\")\n",
    "hls_model = convert_from_pyg_model(torch_model,\n",
    "                                       n_edge=graph_dims['n_edge'],\n",
    "                                       n_node=graph_dims['n_node'],\n",
    "                                       edge_attr=graph_dims['edge_attr'],\n",
    "                                       node_attr=graph_dims['node_attr'],\n",
    "                                       edge_dim=graph_dims['edge_dim'],\n",
    "                                       node_dim=graph_dims['node_dim'],\n",
    "                                       misc_config = misc_config,\n",
    "                                       forward_dictionary=forward_dict, \n",
    "                                       activate_final='sigmoid', #sigmoid\n",
    "                                       output_dir=output_dir,\n",
    "                                       hls_config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0701c",
   "metadata": {},
   "source": [
    "## hls_model.compile() builds the C-function for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7da705cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "outputs_str: result_t layer12_out[N_LAYER_11]\n",
      "layer: <hls4ml.model.hls_layers.Input object at 0x7fdaef459850>\n",
      "layer: <hls4ml.model.hls_layers.Input object at 0x7fdaef459310>\n",
      "layer: <hls4ml.model.hls_layers.Input object at 0x7fdaef459510>\n",
      "layer: <hls4ml.model.hls_layers.NodeEncoder object at 0x7fdaef459250>\n",
      "def_cpp: layer4_t layer4_out[N_LAYER_1_4*N_LAYER_2_4]\n",
      "layer: <hls4ml.model.hls_layers.EdgeEncoder object at 0x7fdaef484410>\n",
      "def_cpp: layer5_t layer5_out[N_LAYER_1_5*N_LAYER_2_5]\n",
      "layer: <hls4ml.model.hls_layers.BatchNorm2D object at 0x7fdaf370c650>\n",
      "def_cpp: layer6_t layer6_out[N_LAYER_1_4*N_LAYER_2_4]\n",
      "layer: <hls4ml.model.hls_layers.BatchNorm2D object at 0x7fdaef459110>\n",
      "def_cpp: layer7_t layer7_out[N_LAYER_1_5*N_LAYER_2_5]\n",
      "layer: <hls4ml.model.hls_layers.EdgeAggregate object at 0x7fdaef4d5e90>\n",
      "def_cpp: layer8_t layer8_out[N_NODE*LAYER8_OUT_DIM]\n",
      "layer: <hls4ml.model.hls_layers.NodeBlock object at 0x7fdaef4a2750>\n",
      "def_cpp: layer9_t layer9_out[N_LAYER_1_4*LAYER9_OUT_DIM]\n",
      "layer: <hls4ml.model.hls_layers.MeanPool object at 0x7fdaef4a2ed0>\n",
      "def_cpp: layer10_t layer10_out[LAYER9_OUT_DIM]\n",
      "final Mean pool template: nnet::mean_pool<layer9_t, layer10_t, config10>(layer9_out, layer10_out);\n",
      "layer: <hls4ml.model.hls_layers.Dense object at 0x7fdaef61fcd0>\n",
      "def_cpp: layer11_t layer11_out[N_LAYER_11]\n",
      "layer: <hls4ml.model.hls_layers.Activation object at 0x7fdaef61f110>\n",
      "Dense config cpp: struct config11 : nnet::dense_config {\n",
      "    static const unsigned n_in = LAYER9_OUT_DIM;\n",
      "    static const unsigned n_out = N_LAYER_11;\n",
      "    static const unsigned io_type = nnet::io_parallel;\n",
      "    static const unsigned strategy = nnet::latency;\n",
      "    static const unsigned reuse_factor = 8;\n",
      "    static const unsigned n_zeros = 0;\n",
      "    static const unsigned n_nonzeros = 1;\n",
      "    static const bool store_weights_in_bram = false;\n",
      "    typedef ap_fixed<52,20> accum_t;\n",
      "    typedef model_default_t bias_t;\n",
      "    typedef model_default_t weight_t;\n",
      "    typedef ap_uint<1> index_t;\n",
      "    static const bool remove_pipeline_pragma = false;\n",
      "    template<class x_T, class y_T, class res_T>\n",
      "    using product = nnet::product::mult<x_T, y_T, res_T>;\n",
      "    static const bool gnn_resource_limit = false;\n",
      "};\n",
      "\n",
      "final Mean pool template: nnet::mean_pool<layer9_t, layer10_t, config10>(layer9_out, layer10_out);\n",
      "Done\n",
      "lib_name: firmware/myproject-dADF410B.so\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncompile\\nbuild\\nimplementation\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.compile()\n",
    "# hls_model.build()\n",
    "\"\"\"\n",
    "compile\n",
    "build\n",
    "implementation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e678b04",
   "metadata": {},
   "source": [
    "# Evaluation and prediction: hls_model.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "51c28847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDS: [0 1 2 3 4 5 6 7 8 9]\n",
      "graphs length: 2\n",
      "writing test bench data for 1st graph\n"
     ]
    }
   ],
   "source": [
    "class data_wrapper(object):\n",
    "    def __init__(self, node_attr, edge_attr, edge_index, target):\n",
    "        self.x = node_attr\n",
    "        self.edge_attr = edge_attr\n",
    "        self.edge_index = edge_index.transpose(0,1)\n",
    "\n",
    "        node_attr, edge_attr, edge_index = self.x.detach().cpu().numpy(), self.edge_attr.detach().cpu().numpy(), self.edge_index.transpose(0, 1).detach().cpu().numpy().astype(np.float32)\n",
    "        node_attr, edge_attr, edge_index = np.ascontiguousarray(node_attr), np.ascontiguousarray(edge_attr), np.ascontiguousarray(edge_index)\n",
    "        self.hls_data = [node_attr, edge_attr, edge_index]\n",
    "\n",
    "        self.target = target\n",
    "        self.np_target = np.reshape(target.detach().cpu().numpy(), newshape=(target.shape[0],))\n",
    "\n",
    "def load_graphs(graph_indir, graph_dims, n_graphs):\n",
    "    graph_files = np.array(os.listdir(graph_indir))\n",
    "    graph_files = np.array([os.path.join(graph_indir, graph_file)\n",
    "                            for graph_file in graph_files])\n",
    "    n_graphs_total = len(graph_files)\n",
    "    IDs = np.arange(n_graphs_total)\n",
    "    print(f\"IDS: {IDs}\")\n",
    "    dataset = GraphDataset(graph_files=graph_files[IDs])\n",
    "\n",
    "    graphs = []\n",
    "    for data in dataset[:n_graphs]:\n",
    "        node_attr, edge_attr, edge_index, target, bad_graph = fix_graph_size(data.x, data.edge_attr, data.edge_index,\n",
    "                                                                             data.y,\n",
    "                                                                             n_node_max=graph_dims['n_node'],\n",
    "                                                                             n_edge_max=graph_dims['n_edge'])\n",
    "        if not bad_graph:\n",
    "            graphs.append(data_wrapper(node_attr, edge_attr, edge_index, target))\n",
    "#         graphs.append(data_wrapper(node_attr, edge_attr, edge_index, target))\n",
    "    print(f\"graphs length: {len(graphs)}\")\n",
    "\n",
    "    print(\"writing test bench data for 1st graph\")\n",
    "    data = graphs[0]\n",
    "    node_attr, edge_attr, edge_index = data.x.detach().cpu().numpy(), data.edge_attr.detach().cpu().numpy(), data.edge_index.transpose(\n",
    "        0, 1).detach().cpu().numpy().astype(np.int32)\n",
    "    os.makedirs('tb_data', exist_ok=True)\n",
    "    input_data = np.concatenate([node_attr.reshape(1, -1), edge_attr.reshape(1, -1), edge_index.reshape(1, -1)], axis=1)\n",
    "    np.savetxt('tb_data/input_data.dat', input_data, fmt='%f', delimiter=' ')\n",
    "\n",
    "    return graphs\n",
    "\n",
    "\n",
    "graph_indir = \"trackml_data/processed_plus_pyg_small\"\n",
    "\n",
    "graphs = load_graphs(graph_indir, graph_dims, n_graphs=10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e31a4c5a",
   "metadata": {},
   "source": [
    "If your model takes a non-singular input (e.g. node attributes, edge attributes, and an edge index), then you should pass it as a list (e.g. [node_attr, edge_attr, edge_index]). See the \"data_wrapper\" class, and note that the hls_model.predict() method is used on the data.hls_data attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23b1428f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEs: \n",
      " [1.1599538e-07, 1.1224763e-07, 7.792384e-09, 1.1599538e-07, 1.1599538e-07, 1.1599538e-07, 1.1245958e-07, 1.1016137e-07, 1.1245958e-07, 1.1245958e-07, 1.1583303e-07, 1.1599538e-07, 1.1599538e-07, 4.7070015e-10, 1.1599538e-07, 1.1245958e-07, 1.1599538e-07, 1.1245897e-07, 1.124595e-07, 1.1599538e-07]\n",
      "Average MSEs: \n",
      " 1.0326101573809865e-07\n"
     ]
    }
   ],
   "source": [
    "with open('test_data.pickle', 'rb') as f:\n",
    "    graphs= pkl.load(f) \n",
    "\n",
    "MSEs = []\n",
    "for data in graphs:\n",
    "    torch_pred = torch_model(data)\n",
    "    torch_pred = torch_pred.detach().cpu().numpy().flatten()\n",
    "    hls_pred = hls_model.predict(data.hls_data)\n",
    "    MSE = mean_squared_error(torch_pred, hls_pred)\n",
    "    MSEs.append(MSE)\n",
    "    \n",
    "print(f\"MSEs: \\n {MSEs}\")\n",
    "print(f\"Average MSEs: \\n {np.mean(MSEs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1a994832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def compare_parameters(torch_parameter, hls_parameter):\n",
    "    if not hls_parameter.endswith('.txt'): hls_parameter += '.txt'\n",
    "\n",
    "    torch_parameter = torch_model.state_dict()[torch_parameter].T.numpy().flatten()\n",
    "    \n",
    "    hls_csv = os.path.join('test_GNN/firmware/weights/',hls_parameter)\n",
    "    hls_parameter = np.genfromtxt(hls_csv, delimiter=',').flatten()\n",
    "\n",
    "    torch_parameter = np.sort(torch_parameter)\n",
    "    hls_parameter = np.sort(hls_parameter)\n",
    "\n",
    "    try:\n",
    "        torch.testing.assert_allclose(torch_parameter, hls_parameter)\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        return torch_parameter, hls_parameter\n",
    "    return \"We Good!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46ee70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9e92136e0d2907d3ff6e54aecabfe210bb12ab86ed2713ef1b4596066386fef"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pyg_to_hls_walkthrough')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
